---
title: "Trump vs. Harris: A Data-Driven Forecast modeling the 2024 US Presidential Elections"
subtitle: "Trump trumps Harris to become the next President of the United States"
author: 
  - Sophia Brothers
  - Deyi Kong
  - Rayan Awad Alim
thanks: "Code and data are available at: [https://github.com/eeeee-cmd/US_Election/](https://github.com/eeeee-cmd/US_Election/)."
date: today
date-format: long
abstract: "This paper predicts the 2024 U.S. Presidential election. We utilizes linear regression model deploying polling data and demographic factors to predict both popular vote and Electoral College outcomes. The findings indicate a close race between Donald Trump and Kamala Harris, and we predict Trump will secure the Electoral College and Popular Vote due to key wins in tight races for the Battleground States. The results emphasize the role of state-level dynamics, particularly in Battleground states, in determining election outcomes."
format: pdf
toc: true
toc-depth: 3
number-sections: true
bibliography: references.bib
---

```{r}
#| include: false
#| warning: false
#| message: false

# Install Packages if not downloaded:
required_packages <- c(
  "tidyverse", "sf", "here", "arrow", "ggplot2", "janitor", "purrr", "knitr", "kableExtra"
) 
for (p in required_packages) {
  if (!require(p, character.only = TRUE)) {
    install.packages(p, character.only = TRUE)
  }
}

library(tidyverse)
library(sf)
library(dplyr)
library(here)
library(arrow)
library(ggplot2)
library(janitor)
library(purrr)
library(knitr)
library(kableExtra)
```

# Introduction

The U.S. presidential election is a pivotal moment not only shapes domestic political landscape but also far-reaching its consequences on a global scale. Republicans and Democrats held primary elections across the country earlier in 2024 that eventually filtered down to the main candidates: Donald Trump and Kamala Harris. The polarized political climate and rapidly shifting public opinion have made predicting outcomes increasingly challenging, where winning key swing states is crucial to securing victory.

The main estimand is the projected support percentage and each candidate's winning probability in terms of state-level victories and Electoral College votes. This paper utilizes linear regression model incorporates numeric value of the credibility of pollsters, number of respondents, poll's recency to estimate the probability of each candidate winning in individual states. The objective is to translate these probabilities into a forecast the overall winner of the election. Our findings reveal a close race, with Trump holding a slight edge in both the popular vote and Electoral College due to projected victories in key swing states.

Trump's path to victory hinges on critical wins in states such as Pennsylvania, Georgia, and Wisconsin, where his projected margins are narrow but statistically significant. Meanwhile, Harris secures strong performances in populous Democratic strongholds like California and New York, but these do not offset Trump’s advantage in less populous yet crucial battleground states. This result underscores the significant influence of swing states and the Electoral College system in determining the outcome, particularly in closely contested elections. These insights contribute to a broader understanding of how statistical modeling can inform political strategy and election analysis.

The structure of the paper is as follows: [@sec-data] outlines the data sources and variables considered, followed by the model setup in [@sec-modset] and justification in [@sec-modjust]. The results in [@sec-result] presents the key findings of the analysis, with a discussion on the implications. [@sec-discussion] then discusses potential limitations and suggestions for future research. [@sec-appx] provides additional detailed information about the data, model and methodology.

# Data {#sec-data}

## Overview

The data used in this analysis comes from a combination of publicly available polling data for the 2024 U.S. Presidential election [@FiveThirtyEightPolls]. The analysis leverages the statistical programming language R [@citeR] and several libraries, including `tidyverse` [@tidyverse], `janitor` [@janitor], `knitr` [@knitr], `dplyr` [@dplyr], `arrow` [@arrow], `purrr` [@purrr], and `here` [@here], for data manipulation. `ggplot2` [@ggplot] and `kableExtra` [@kableExtra] for visualization. The dataset covers various polls conducted across multiple states, capturing the support for each major candidate—Donald Trump and Kamala Harris—along with detailed attributes of the polls.

## Measurement

The primary measurement process reflects the transformation of raw polling data into structured entries to actionable insights for election forecasting. We first select and rename key variables from raw data to focus on relevant information, such as pollster, pollscore, state, polling dates, sample size, and candidate support percentage. These variables represent essential poll characteristics that capture public sentiment in response to real-world campaign dynamics and demographic differences across states.

To address instances where the original data referenced Joe Biden instead of Kamala Harris, we assumed the entries for Biden will goes to Harris in consequences of Democratic Party. This approach is supported by "Harris’s truncated presidential campaign relies heavily upon President Biden’s policy framework and she eaddress the campaign’s weaknesses and win over critical voter demographics [@RealInstitutoElcano]. Thus, substituting Biden’s polling data with Harris’s ensures continuity in demographic appeal without altering established polling trends. Then we filter to include only polls relevant to the two candidates，Trump and Harris, and features like PollRecency were constructed to weigh recent polls higher. The data was cleaned by removing irrelevant or incomplete observations, and new variables were constructed where necessary.

## Outcome Variables

The main outcome variable of interest is the Percentage of support each candidate has in a given poll, which represents the proportion of respondents who favor one candidate over the other. This variable is crucial for estimating both the popular vote and Electoral College outcomes. We see a bimodal distribution in @fig-percentage. This indicates that candidates are either recieveing very high percentages of support or very low percentages of support. When we pull out Harris and Trump and view their distributions versus all candidates in @fig-candidatepercentage, we see that these two candidates see statistically high percentages of support, indicating they are leading the polls.

## Predictor Variables

In this analysis, several key predictors were identified to evaluate polling data effectively. The first variable, **PollScore**, is a numeric representation of the pollster's credibility, which stands for "Predictive Optimization of Latent Skill Level in Surveys, Considering Overall Record, Empirically." This score helps assess the error and bias associated with a specific pollster, where lower values (including negative numbers) indicate better credibility [@PollsterRating]. @fig-pollscoredistribution reveals whether the majority of pollsters tend to have high or low credibility scores. We see a higher concentration of negative scores, which suggests a trend toward more reputable pollsters in the dataset.

Next, **SampleSize** refers to the number of respondents involved in each poll. A larger sample size generally enhances the reliability of poll results, as it is more likely to represent the broader population accurately. In @fig-samplesize we see that the vast majority of polls in the dataset have a sample size of less than 2500. As discussed in @sec-appx, this number maximizes efficiency and accuracy while minimizing the margin of error. The **State** variable denotes the U.S. state where the poll was conducted, in order to give geographical context. All 50 states are represented in this analysis, and Nebraska and Maine are broken up into electoral districts. Washington DC is not included in this dataset. @fig-statesample shows the number of polls conducted in each state. Battleground states notably have a higher number of polls conducted.

**PollRecency** is a variable we created to measure the number of days between the start date of the poll and the present. This is important as more recent polls tend to reflect the current political climate and voter sentiment more accurately than polls that were conducted a year ago, or more. In @fig-pollrecency we see that the majority of polls were conducted more recently than not, however polls date back until the last presidential election in 2020. Lastly, **NumericGrade** is a numerical assessment of the pollster's reliability. Our dataset displays polls that tend to have a higher numeric grade as depicted in @fig-numericgrade.

While **CandidateName** is not a predictor variable within the model, it serves as a filter for the predictions being analyzed. This allows us to compare between the two primary candidates—Donald Trump and Kamala Harris.

@fig-corrmatrix reveals relationships among the key variables in the dataset. The strong negative correlation between PollScore and NumericGrade (-0.89) indicates that as the PollScore of the pollster decreases (lower PollScore values are better), the reliability of the pollster increases (higher NumericGrade values are preferable). This shows that more credible pollsters are likely to be more reliable, which makes sense given the context.

PollRecency exhibits a weak positive correlation with SampleSize (0.07) and Percentage (0.23), suggesting that more recent polls are slightly associated with a larger number of respondents and may result in higher outcome percentages (which may be due to a reduction in the number of candidates as the election grows closer). However, the correlation with PollScore is very weak (-0.05), indicating that the recency of polls does not significantly impact their credibility or reliability.

Percentage, as the outcome variable, shows a weak positive correlation with SampleSize (0.16), suggesting that larger sample sizes may be associated with higher percentages, although the effect is modest. There is a slight negative correlation with PollScore (-0.02), reinforcing the notion that higher percentages do not consistently relate to the reliability of the pollsters.

# Model

To predict the outcome of the 2024 U.S. Presidential election, we developed two linear regression models: one for Kamala Harris and one for Donald Trump. These models aim to estimate the percentage of support for each candidate based on the aforementioned predictor variables.

## Model Set-Up {#sec-modset}

This paper utilizes linear regression models:

$$Percentage_H = \beta_0 + \beta_1 Pollscore_i + \beta_2 SampleSize + \beta_3 Numeric Grade_i + \beta_4 State_i + \beta_5PollRecency + \epsilon_i$$

$$Percentage_T = \beta_0 + \beta_1 Pollscore_i + \beta_2 SampleSize + \beta_3 Numeric Grade_i + \beta_4 State_i + \beta_5PollRecency + \epsilon_i$$

In this model, $Percentage$ represents the predicted support percentage for a candidate in a given poll. $Percentage_H$ and $Percentage_T$ represent the predicted support for Harris and Trump respectively. Each predictor variable is carefully selected to capture critical factors influencing voter support, with coefficients $\beta_i$ representing the strength of each factor's impact. The error term $\epsilon_i$ accounts for random variability not explained by the model.

For a more granular analysis, separate linear regression models were constructed for each of the two primary candidates, Harris and Trump, to predict their state-by-state poll percentages. These models allow for a detailed view of each candidate’s performance across states. Based on these percentages, we forecast the likely winner of the popular vote as well as the state’s electoral votes. These models filter for $CandidateName$ since the model is candidate-specific.

As defined in [@sec-data], each predictor variable has been chosen to reflect characteristics that influence election polling.

## Model Justification {#sec-modjust}

While other complex models could be appropriate in this instance, these models were chosen for its balance between simplicity and predictive power. Linear regression allows us to capture relationships between polling quality, sample size, and recency, while still providing interpretable coefficients. Given the nature of polling data, this approach is both appropriate and commonly used in election forecasting. A linear model allows us to directly interpret the influence of each predictor on voter support.

## Assumptions and Limitations

This model operates under several assumptions, including that relationships between predictors and outcomes are linear, errors are normally distributed, and predictors are not excessively collinear. Potential limitations include the fact that linear regression may oversimplify relationships in polling data, especially if interactions between predictors exist. Furthermore, as the model relies on historical polling data, it assumes that past trends are indicative of future behavior, which may not hold true if significant political events alter voter preferences unexpectedly, as discussed in [@sec-discussion].

## Model Validation

The model was implemented using R, with out-of-sample testing and Root Mean Square Error (RMSE) calculations applied to assess predictive accuracy as predicted in @tbl-rmse. By splitting the data into training and test sets, we evaluated how well the model performs on unseen data. This approach helps ensure that the model generalizes effectively to new data and avoids overfitting.

```{r}
#| label: tbl-rmse
#| tbl-cap: The RMSE for each model
#| echo: false
#| eval: true
#| warning: false
#| message: false
rmse_results <- read_parquet(here::here("data/analysis_data/rmse_results.parquet"))

rmse_results %>%
  kable(caption = "RMSE Results for Candidate Models",
        col.names = c("Model", "Root Mean Squared Error (RMSE)"),
        digits = 2) %>%
  kable_styling(latex_options = c("striped", "scale_down"))

```

```{r}
#| label: tbl-popularvote
#| tbl-cap: The percentage of support Harris and Trump receive overall
#| echo: false
#| eval: true
#| warning: false
#| message: false

cleaned_data <- read_parquet(here::here("data/analysis_data/electoral_data.parquet"))
lm_model_trump <- readRDS(here::here("models/lm_model_trump.rds"))
lm_model_harris <- readRDS(here::here("models/lm_model_harris.rds"))

cleaned_data <- cleaned_data %>%
  mutate(PredictedTrumpPercentage = predict(lm_model_trump, newdata = cleaned_data),
         PredictedHarrisPercentage = predict(lm_model_harris, newdata = cleaned_data))

results <- cleaned_data %>%
  summarise(
    NationalTrumpAverage = mean(PredictedTrumpPercentage, na.rm = TRUE),
    NationalHarrisAverage = mean(PredictedHarrisPercentage, na.rm = TRUE)
  )

total_percentage <- sum(results$NationalTrumpAverage, results$NationalHarrisAverage, na.rm = TRUE)
results <- results %>%
  mutate(
    NormalizedTrumpPercentage = (NationalTrumpAverage / total_percentage) * 100,
    NormalizedHarrisPercentage = (NationalHarrisAverage / total_percentage) * 100
  )

results %>%
  select(NationalTrumpAverage, NormalizedTrumpPercentage, NationalHarrisAverage, NormalizedHarrisPercentage) %>%
  kable(
    caption = "Predicted National Popular Vote for Donald Trump and Kamala Harris",
    col.names = c("Trump Average Predicted %", "Trump Normalized %", "Harris Average Predicted %", "Harris Normalized %"),
    digits = 2,
    booktabs = TRUE
  ) %>%
  kable_styling(latex_options = c("striped", "scale_down"))

```

```{r}
#| label: tbl-electoral
#| tbl-cap: The number of electoral college votes Harris vs Trump recieves
#| echo: false
#| eval: true
#| warning: false
#| message: false

cleaned_data <- read_parquet(here::here("data/analysis_data/electoral_data.parquet"))
lm_model_trump <- readRDS(here::here("models/lm_model_trump.rds"))
lm_model_harris <- readRDS(here::here("models/lm_model_harris.rds"))

unique_states <- distinct(cleaned_data, State)

prediction_data <- cleaned_data %>%
  group_by(State) %>%
  summarise(
    PollScore = mean(PollScore, na.rm = TRUE),
    SampleSize = mean(SampleSize, na.rm = TRUE),
    NumericGrade = mean(NumericGrade, na.rm = TRUE),
    PollRecency = mean(PollRecency, na.rm = TRUE),
    .groups = 'drop'
  )

prediction_data <- prediction_data %>%
  mutate(
    TrumpPredicted = predict(lm_model_trump, newdata = prediction_data),
    HarrisPredicted = predict(lm_model_harris, newdata = prediction_data)
  )

electoral_votes <- tibble(
  State = c("Alabama", "Kentucky", "North Dakota", "Alaska", "Louisiana", 
            "Ohio", "Arizona", "Maine", "Oklahoma", "Arkansas", 
            "Maryland", "Oregon", "California", "Massachusetts", "Pennsylvania", 
            "Colorado", "Michigan", "Rhode Island", "Connecticut", "Minnesota", 
            "South Carolina", "Delaware", "Mississippi", "South Dakota", 
            "District of Columbia", "Missouri", "Tennessee", "Florida", 
            "Montana", "Texas", "Georgia", "Nebraska", "Utah", 
            "Hawaii", "Nevada", "Vermont", "Idaho", "New Hampshire", 
            "Virginia", "Illinois", "New Jersey", "Washington", 
            "Indiana", "New Mexico", "West Virginia", "Iowa", 
            "New York", "Wisconsin", "Kansas", "North Carolina", 
            "Wyoming"),
  Votes = c(9, 8, 3, 3, 8, 
            17, 11, 4, 7, 6, 
            10, 8, 54, 11, 19, 
            10, 15, 4, 7, 10, 
            9, 3, 6, 3, 
            3, 10, 11, 30, 
            4, 40, 16, 5, 6, 
            4, 6, 3, 4, 4, 
            13, 19, 14, 12, 
            11, 5, 4, 6, 
            28, 10, 6, 16, 
            3)
)

predictions_with_votes <- prediction_data %>%
  left_join(electoral_votes, by = "State")

predictions_with_votes <- predictions_with_votes %>%
  mutate(
    Winner = case_when(
      TrumpPredicted > HarrisPredicted ~ "Donald Trump",
      HarrisPredicted > TrumpPredicted ~ "Kamala Harris",
      TRUE ~ "Tie"
    ),
    TrumpElectoralVotes = if_else(Winner == "Donald Trump", Votes, 0),
    HarrisElectoralVotes = if_else(Winner == "Kamala Harris", Votes, 0)
  )

electoral_totals <- predictions_with_votes %>%
  summarise(
    TrumpTotalElectoralVotes = sum(TrumpElectoralVotes, na.rm = TRUE),
    HarrisTotalElectoralVotes = sum(HarrisElectoralVotes, na.rm = TRUE)
  )

electoral_totals %>%
  kable(
    caption = "Predicted Number of Electoral Votes for Donald Trump and Kamala Harris",
    col.names = c("Trumps Total Electoral Votes", "Harris Total Electoral Votes"),
    digits = 2,
    booktabs = TRUE
  ) %>%
  kable_styling(latex_options = c("striped", "scale_down"))
```

```{r}
#| label: tbl-statewinners
#| tbl-cap: The winners of each state, which determines who gets the electoral college votes for that state.
#| echo: false
#| eval: true
#| warning: false
#| message: false

state_winners <- predictions_with_votes %>%
  select(State, TrumpPredicted, HarrisPredicted) %>%
  mutate(
    Winner = case_when(
      TrumpPredicted > HarrisPredicted ~ "Donald Trump",
      HarrisPredicted > TrumpPredicted ~ "Kamala Harris",
      TRUE ~ "Tie"
    )
  )
#print(state_winners, n=54)

state_winners %>%
  slice(1:53) %>%
  kable(
    caption = "Predicted Percentage of Electoral Votes Per State",
    col.names = c("State", "Trump Predicted %", "Harris Predicted %", "Winner"),
    digits = 2,
    booktabs = TRUE
  ) %>%
  kable_styling(latex_options = c("striped", "scale_down"))
```

# Results {#sec-result}

The national averages for both candidates, as shown in @tbl-popularvote, show that Donald Trump is predicted to receive an average of 45.26% of the popular vote, which, when normalized, represents 50.96% of the total forecasted support, while Kamala Harris is predicted to receive 43.56% with a normalized value of 49.04%. In terms of electoral votes, @tbl-electoral shows that Donald Trump is projected to secure 302 votes, while Kamala Harris is expected to gain 233 votes.

The predicted outcomes for each state are summarized in @tbl-statewinners. Donald Trump leads in several key battleground states, including Pennsylvania (45.68% for Trump vs. 44.83% for Harris), Georgia (46.94% vs. 43.49%), and Michigan (44.86% vs. 43.87%), while Kamala Harris secures leads in states such as Wisconsin (45.50% for Harris vs. 45.33% for Trump) and Minnesota (44.73% vs. 41.64%). @fig-predictedscoremap is a visual representation of how these state outcomes appear on an electoral map.

The polling data includes an average poll score of -0.379, with an average sample size of approximately 1,605 individuals per poll. The average percentage of support across all states for the candidates is 33.68%. This dataset contains a total of 15,829 individual polls, allowing for the model to be trained off a significant number of datapoints. The summary statistics are displayed in @tbl-sum.

```{r}
#| label: tbl-sum
#| tbl-cap: summary statistics for the cleaned data
#| echo: false
#| eval: true
#| warning: false
#| message: false
cleaned_data <- read_parquet(here::here("data/analysis_data/president_polls_cleaned.parquet"))

summary_stats <- cleaned_data %>%
  summarise(
    AveragePollScore = mean(PollScore, na.rm = TRUE),
    AverageSampleSize = mean(SampleSize, na.rm = TRUE),
    AveragePercentage = mean(Percentage, na.rm = TRUE),
    TotalPolls = n()
  )

# print(summary_stats)

summary_stats %>%
  kable(
    caption = "Summary Statistics of Model Results",
    col.names = c("Average Poll Score", "Average Sample Size", "Average Percentage", "Total Polls"),
    digits = 3,
    booktabs= TRUE
  ) %>%
  kable_styling(latex_options = c("striped", "scale_down"))
```

```{r}
#| label: fig-predictedscoremap
#| fig-cap: "Mapped Model-predicted outcomes for 2024 elections by State"
#| echo: false
#| eval: true
#| warning: false
#| message: false

states_map <- map_data("state")

electoral_data <- predictions_with_votes
electoral_data$State <- tolower(electoral_data$State) # matching state names

merged_data <- inner_join(states_map, electoral_data, by = c("region" = "State"))

map <- ggplot(merged_data, aes(x = long, y = lat, group = group)) +
  geom_polygon(aes(fill = Winner), color = "white") +
  scale_fill_manual(values = c("Donald Trump" = "red", "Kamala Harris" = "blue")) +
  labs(title = "2024 US Presidential Election Predictions by State",
       fill = "Predicted Winner") +
  theme_void() +
  theme(legend.position = "right")

map
```

```{r}
#| label: fig-pollscoredistribution
#| fig-cap: Distribution of Poll Scores by Candidate with denisty overlayed
#| echo: false
#| eval: true
#| warning: false
#| message: false

Select_candidates_cleaned_data <- cleaned_data %>%
  filter(CandidateName %in% c("Donald Trump", "Kamala Harris"))

ggplot(Select_candidates_cleaned_data, aes(x = PollScore)) +
  geom_histogram(aes(y = ..density..),
                 bins = 30,
                 fill = "blue",
                 color = "black",
                 alpha = 0.7) +
    geom_density(color = "black", fill = "salmon", alpha = 0.6) +
  labs(title = "Distribution of Poll Scores by Candidate",
       x = "Poll Score", 
       y = "Frequency") +
  theme_minimal() +
  facet_wrap(~ CandidateName)
```

```{r}
#| label: fig-samplesize
#| fig-cap: The distribution of sample sizes used in each poll
#| echo: false
#| eval: true
#| warning: false
#| message: false


ggplot(cleaned_data, aes(x = SampleSize)) +
  geom_histogram(bins = 30,
                 fill = "green",
                 color = "black",
                 alpha = 0.7) +
  labs(title = "Distribution of Sample Size",
       x = "Sample Size", 
       y = "Frequency")+
  theme_minimal()
```

```{r}
#| label: fig-numericgrade
#| fig-cap: The distribution of numeric grades assigned to each poll
#| echo: false
#| eval: true
#| warning: false
#| message: false

ggplot(cleaned_data, aes(x = NumericGrade)) +
  geom_histogram(bins = 30,
                 fill = "purple",
                 color = "black",
                 alpha = 0.7) +
  labs(title = "Distribution of Numeric Grade",
       x = "Numeric Grade", 
       y = "Frequency")+
  theme_minimal()
```

```{r}
#| label: fig-percentage
#| fig-cap: The distribution of what percentage of support a candidate recieves in a poll
#| echo: false
#| eval: true
#| warning: false
#| 
#| 
#| message: false
ggplot(cleaned_data, aes(x = Percentage)) +
  geom_histogram(bins = 30,
                 fill = "orange",
                 color = "black",
                 alpha = 0.7) +
  labs(title = "Distribution of Percentage", 
       x = "Percentage",
       y = "Frequency") +
  theme_minimal()
```

```{r}
#| label: fig-candidatepercentage
#| fig-cap: violin plot displaying the percentage of support Harris and Trump receive compared to all candidates
#| echo: false
#| eval: true
#| warning: false
#| message: false

harris_trump_selection <- cleaned_data %>%
  filter(CandidateName %in% c("Donald Trump", 
                              "Kamala Harris"))

all_candidates <- cleaned_data %>%
  mutate(CandidateName = "All Candidates")

combined_data <- bind_rows(
  harris_trump_selection,
  all_candidates
)

ggplot(combined_data, aes(x = CandidateName, 
                          y = Percentage, 
                          fill = CandidateName)) +
  geom_violin(alpha = 0.5) +
  geom_boxplot(width = 0.1, color = "black", outlier.shape = NA) +
  labs(title = "Percentage by Candidate", 
       x = "Candidate", 
       y = "Percentage") +
  theme(axis.text.x = element_text(angle = 45, hjust = 1)) +
  scale_fill_manual(values = c("grey", "salmon", "blue")) +
  facet_wrap(~CandidateName, scales = "free_x") +
  theme_minimal()
```

```{r}
#| label: fig-statesample
#| fig-cap: The number of polls conducted in each state.
#| echo: false
#| eval: true
#| warning: false
#| message: false

poll_counts <- cleaned_data %>%
  group_by(State) %>%
  summarise(Count = n())

ggplot(poll_counts, aes(x = State, y = Count)) +
  geom_bar(stat = "identity") +
  labs(title = "Number of Polls by State", x = "State", y = "Number of Polls") +
  theme(axis.text.x = element_text(angle = 45, hjust = 1, vjust = 1, size = 6))

```

```{r}
#| label: fig-corrmatrix
#| fig-cap: correlation between PollScore, the sample size of the poll, and the percentage of support for a candidate
#| echo: false
#| eval: true
#| warning: false
#| message: false
numerical_data <- cleaned_data %>%
  select(PollScore, SampleSize, PollRecency, NumericGrade)

correlation_matrix <- cor(numerical_data, use = "complete.obs")

library(ggcorrplot)
ggcorrplot(correlation_matrix, lab = TRUE, title = "Correlation Matrix")
```

```{r}
#| label: fig-pollrecency
#| fig-cap: The distribution of how recent a poll was conducted
#| echo: false
#| eval: true
#| warning: false
#| message: false

ggplot(cleaned_data, aes(x = PollRecency)) +
  geom_histogram(bins = 30,
                 fill = "pink",
                 color = "black",
                 alpha = 0.7) +
  labs(title = "Distribution of Poll Recency",
       x = "PollRecency", 
       y = "Frequency")+
  theme_minimal()
```

\newpage

# Discussion {#sec-discussion}

## What did we do?

This paper analyzes and predicts the 2024 U.S. presidential election outcomes through regression models based on polling data for two main candidates, Donald Trump and Kamala Harris. Using a state-by-state approach, it evaluates each candidate’s predicted percentage of support and calculates the anticipated electoral votes to provide an overall electoral projection. The model incorporates the predictor factors: PollScore, NumericGrade, SampleSize, State, and PollRecency.

## What did we learn?

This paper reveals the regional polarization in the U.S. and illustrates how strong state-based support can determine election outcomes, especially in battleground states. From this analysis, we observe that regions such as the Midwest and the South tend to favor conservative candidates, while the Northeast and West Coast are typically more supportive of liberal candidates. Trump’s predicted success in key battleground states, such as Pennsylvania and Michigan, leads to a victory in the Electoral College. Meanwhile, the difference in the predicted percentages for the popular vote is less than 2%. Although the popular vote is predicted to be nearly balanced, with a margin of less than 2% separating the candidates, the narrow margins in key battleground states demonstrate why every vote is so important. Small shifts in turnout or voter sentiment can truly change the overall outcome of the election, and thus the future of the United States, dramatically. A prime example of this took place in Georgia.

In 2020, Georgia turned blue in a presidential election for the first time since 1992 [@georgia2020]. A major factor in this shift was the influx of young, diverse individuals in the Atlanta suburban area. In Gwinnett County, the non-Hispanic white population decreased from 67% in 2000 to around 35% by 2020 [@georgiaturnedblue]. Mitt Romney, a Republican, had won Gwinnett County by 9 points in 2012. In 2020, it shifted to an 18-point win for Joe Biden. Additionally, there was a major campaign by Stacey Abrams to mobilize previously disengaged voters, particularly people of color [@georgiaturnedblue]. All of this led to Georgia becoming a swing state after 28 years of voting red. Biden received only 0.2% more of the vote than Trump in Georgia.

## What are some weaknesses?

One limitation is its reliance on polling data, which can be inherently biased due to sampling issues, response rates, and potential biases in who chooses to respond to polls. Moreover, as the election date approaches, polling data may fail to capture recent shifts in voter sentiment resulting from unforeseen events or major campaign developments. For example, last-minute political controversies or debates can alter public opinion quickly.

For instance, a recent incident involving derogatory comments about Puerto Rico made at a Trump rally has rapidly influenced the views of Puerto Rican voters in Pennsylvania. Puerto Rican voters, who make up nearly half a million people in the state, have voiced anger and disapproval, with some even reversing their voting plans [@Hill2024]. WhatsApp groups, morning radio shows, and community discussions have amplified these sentiments, illustrating how quickly backlash can spread through influential networks, particularly in swing states [@Hill2024]. Our model predicts Trump will win Pennsylvania by a margin of 0.8%, which is less than the 3.7% of Pennsylvania's Population that Puerto Ricans make up [@USCensus2020]. Situations like these could easily cause Pennsylvania's 19 electoral votes to swing the other way.

Another limitation is the assumption that past trends will remain consistent across elections, which does not account for the ongoing demographic and ideological shifts within states. For instance, the influx of highly educated individuals into certain states can shift voting patterns over time, as research indicates that Americans with a college degree or higher are more likely to vote for liberal candidates [@pew2016]. Should a state’s population of college-educated voters grow significantly, this change could lead to unexpected voting outcomes that our model might not fully capture.

Additionally, the model excludes third-party candidates, who, while unlikely to win, often garner a small but meaningful percentage of votes. Independent candidates historically attract around 2-5% of the popular vote, diverting votes from major party candidates, which can be especially impactful in closely contested states. This factor may lead to underestimations in one candidate’s projected vote share if independents disproportionately draw support from one side.

These limitations point to a larger issue: that forecasting an election relies on data subject to change and that unexpected events and demographic trends can disrupt otherwise reliable patterns.

## What is left to learn? How should we proceed in the future?

Future research could better the model by incorporating live data updates and adjusting for factors such as voter turnout projections and demographic shifts at the state level. For example, as states experience growth in college-educated residents or younger populations, these demographic factors may gradually influence overall voting patterns. A model that can adapt ro reflect these trends could improve predictive accuracy over time. Additionally, including third-party candidates in the model would provide a more well-rounded view of the vote breakdown, as these candidates can meaningfully impact the final distribution of votes between the two primary candidates. As previously mentioned, third-party candidates can capture a small but notable portion of votes, which can tilt tight races in battleground states. Future models could potentially account for this by assessing third-party candidates’ historical performance to estimate the effect on major candidates’ vote shares.

\newpage

# Appendix {#sec-appx}

## Data Cleaning Notes

We began by importing the raw dataset using the read_csv function from the tidyverse package. To focus our analysis on more relevant variables, we selected specific columns, such as poll identifiers and polling metrics, omitting any unnecessary columns.

We then renaming columns for clarity. For example, we changed pct to Percentage, making it easier for anyone working with the data to understand what each variable represents.

We converted date data into date format since they were represented as strings in the raw dataset. This was done by using the mdy() function, after which we removed any rows with missing values for StartDate, EndDate, or ElectionDate to avoid issues later in our analysis.

We also modified the CandidateName variable to attribute polls for Joe Biden to Kamala Harris, as Joe Biden dropped out of the race and Harris replaced him as the democratic nominee.

We also created a new variable called PollRecency, which indicates how many days have passed since each poll started. This was done because as we get closer to election date, polls become more meaningful as they represent the most recent viewpoints of voters. 

We also wrapped the cleaning process in a tryCatch block in order to mitigate any errors that arose throughout the cleaning process.

After completing the cleaning, we saved the final dataset in both Parquet and CSV formats for later analysis.

## Pollster Methodology

The New York Times/Siena College Poll was ranked the most accurate political pollster in the US following the 2022 midterm elections [@PollsterRating]. They received the max 538 rating of 3 stars, one of only four pollsters to do so. They also had a pollscore of -1.5, meaning they had the least amount of error and bias attributed to them of the 282 pollsters ranked by 538 [@PollsterRating].

The Times/Siena Poll targets registered voters in the United States, emphasizing those in battleground states during presidential elections. Since the US decides it's President based on the Electoral College rather than the national popular vote, this is an important focus in order to correctly determine election outcomes. The sampling frame is derived from a voter file which containing lists of 200 million registered voters as well as their demographic information and prior voting behavior data [@TimesSienaPoll].

Each poll typically surveys around 1,000 respondents, which is deemed sufficient for achieving a margin of sampling error of approximately 3-4 percentage points. The Times found that tripling the sample size would only reduce the margin of error by a percent or two. This sample size allows for a balance between representation and efficiency [@TimesSienaPoll].

Respondents are recruited through live phone interviews conducted by trained interviewers from call centers in various states. The polling effort includes both landline and cellphone calls, with over 90% of respondents being reached via cellphones [@TimesSienaPoll].

Times/Siena uses a stratified random sampling technique, where the sample is divided into strata based on demographics such as age, race, gender, and party affiliation. This helps to ensure proportional representation from each group. Stratification helps in achieving a sample that mirrors the voting population, minimizing biases related to demographic variables (i.e. uneducated voters are less likely to respond to polls). However, it faces limitations as stratification increases the complexity of the sampling process, and if strata are not adequately represented in the sample, the results may still skew. Times/Siena combats this by applying weighting adjustments post-survey to correct for any demographic discrepancies [@TimesSienaPoll].

Given the declining response rates typical of phone surveys, the Times/Siena Poll faces challenges in reaching respondents. Approximately 2% of those contacted ultimately participate. This pollster uses follow-up calls to make multiple attempts to reach individuals who initially do not respond [@TimesSienaPoll]. In 2022, they conducted an experiment to find out if responses were skewed by non-response bias [@NonResponseBias]. This was done via a mail survey that offered a reward of up to \$25 for a response. This saw a 30% response rate, which is significantly larger than the 2% response rate Times/Siena gets over phone. Although there were differences between the types of respondents you get between the two methodologies, there was not a meaningful difference in who these respondants claim they would vote for [@NonResponseBias].

The questionnaires used by Times/Siena are designed to capture a broad range of opinions while remaining concise. Interviews are kept under 15 minutes to reduce survey fatigue and maximize response rates [@TimesSienaPoll]. This pollster prioritizes making sure every viewpoint is accurately represented in order to make the questions fair and ensure that respondents are not being swayed in a particular direction. This means the questions must remain objective and clear. However, a survey with limited response options and questions may mean a respondent's view is not captured in its full breadth. It also means that more nuanced opinions may be overlooked in favor of broader trends.

The New York Times/Siena College Poll is rated the most accurate pollster in the US for a reason - it has a well-defined methodology with a fleshed out population frame, sampling approach, and contingencies for non-response handling.

## Idealized Methodology

The idealized methodology for forecasting the US presidential election targets eligible registered voters from all 50 states and Washington D.C., ensuring representation from each state in order to create an Electoral College forecast, with particular emphasis on swing (battleground) states.

The sampling method will utilize stratified random sampling, which stratifies the sample by state. Voters will be further stratified based on factors such as age, gender, race/ethnicity, income, and political affiliation. In swing states, we will ensure oversampling to capture more granular data and reduce our margin of error.

To maintain a national margin of error of ±4%, based on the experiment conducted by Times/Siena, the total sample size will be 1,000 respondents per state [@TimesSienaPoll]. Swing states will be oversampled, with over 2,000 respondents to achieve a margin of error of ±2%. Given an estimated response rate of 2%, we aim to recruit approximately 50,000 potential respondents per state, with a target of 100,000 in battleground states.

To recruit respondents, we will utilize online panel providers like YouGov, Ipsos, and Dynata to obtain geographically and demographically targeted participants. Additionally, we will conduct state-specific phone surveys, employing interactive voice response (IVR) systems and live calls to reach older and less tech-savvy voters, particularly in states with a higher proportion of rural populations. To incentivize participation, all respondents will be entered into state-level sweepstakes, with one winner selected per state.

Data collection will be conducted on platforms such as Google Forms. Telephone surveys will follow the layout and workflow of the Google Form survey. The survey is designed to take approximately five to ten minutes to complete in order to minimize drop-off rates. It will include national-level questions, covering voting intent, candidate preference, key issues, and voter perceptions. After collection, the data will be weighted by state and demographic factors to ensure accuracy, utilizing the latest Census data and state voting records.

For data validation, we will implement several measures, including completion time checks to identify speeding responses, IP tracking to prevent duplicate entries, and reCAPTCHA to guard against bots. Respondents will provide their state of residence and ZIP code for additional verification. Furthermore, the data will be weighted according to state demographics and previous election turnout data, utilizing information from Census and state voting records. Special attention will be paid to swing states to ensure no key voter segments are underrepresented.

In terms of budget allocation, we will designate funds as follows:

1.  Survey Development: \$7,000
    -   The \$7,000 covers the costs associated with designing the survey, including the creation of questions, structuring the survey for clarity and flow, and ensuring that it meets methodological standards. It may also include hiring experts in survey design or consulting with statisticians to validate the survey framework and ensure questions are unbiased. Additionally, while Google Forms is free, this budget may account for platform costs if needed.
2.  Accurate Sampling: \$10,000
    -   The sampling budget is allocated for the costs associated with selecting a representative sample of voters. This includes expenses related to stratified random sampling, where the sample is segmented by various demographics and state representation. In order to ensure each demographic share is accurately represented, we may need to purchase access to demographic data or employ statisticians to ensure that the sampling aligns with the population of each state.
3.  Recruiting Respondents: \$45,000
    -   The majority of the budget is dedicated to recruiting respondents, which is necessary for achieving a large and demographically representative sample. This cost will cover payments to online panel providers which charge fees for access to their respondent pools. Additionally, this budget will cover costs related to conducting state-specific phone surveys and IVR calls, such as hiring call center staff or IVR technology.
4.  Respondent Incentives: \$28,000
    -   To encourage participation, we plan to run state-level sweepstakes, where respondents have a chance to win prizes for completing the survey. A \$500 prize will be awarded to one winner in each state (+ Washington DC). The remaining budget will cover administrative expenses associated with running the sweepstakes.
5.  Data Analysis and Reporting: \$10,000
    -   This portion of the budget is reserved for the costs related to analyzing the collected data and reporting the findings. This may include hiring data analysts or consultants who specialize in statistical analysis and survey data interpretation. The funds will also cover software tools necessary for data analysis, as well as the creation of visualizations and reports to communicate the results effectively.

An example of the survey can be found at this link: <https://forms.gle/igzK683kHLYytGvu8>

\newpage

# References
